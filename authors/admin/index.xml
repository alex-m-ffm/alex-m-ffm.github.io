<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Alex Melemenidis&#39;s homepage</title>
    <link>https://alex.melemenidis.de/authors/admin/</link>
    <description>Recent content on Alex Melemenidis&#39;s homepage</description>
    <generator>Source Themes academia (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>Copyright &amp;copy; {year}</copyright>
    <lastBuildDate>Tue, 19 Mar 2024 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://alex.melemenidis.de/authors/admin/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Why I am not viral on Youtube - A Data Analysis</title>
      <link>https://alex.melemenidis.de/post/2024-03-19-why-i-am-not-viral/</link>
      <pubDate>Tue, 19 Mar 2024 00:00:00 +0000</pubDate>
      
      <guid>https://alex.melemenidis.de/post/2024-03-19-why-i-am-not-viral/</guid>
      <description>


&lt;p&gt;&lt;em&gt;Find the code for my analysis on my &lt;a href=&#34;https://github.com/alex-m-ffm/Youtube_Analysis&#34;&gt;Github repo&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction:&lt;/h2&gt;
&lt;p&gt;As a passionate amateur dragonboat paddler and video editor, I have over the years created more and more videos (currently 61 published) to show the world the competitions and travels of my awesome team. Over time my editing skills have increased through hands-on training, following YouTube tutorials of other creators and a great &lt;a href=&#34;https://www.udemy.com/course/davinci-resolve-training-course/?kw=Video+Editing+in+DaVinci+Resolve+18%2F17%3A+Beginner+to+Advanced&amp;amp;src=sac&amp;amp;couponCode=LETSLEARNNOWPP&#34;&gt;Udemy course&lt;/a&gt;, I have advanced from editing on beginner tools like the Premiere Elements to DaVinci Resolve, a tool also used by media professionals. Further, I have also invested in the lifetime access to &lt;a href=&#34;https://audiio.com/browse&#34;&gt;royalty-free music&lt;/a&gt; so that I can have new soundtracks that could also be fine if I ever managed to monetize my channel.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/4UYevtuy5Dg&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;
Yet, this improvement in video quality did not translate into the traffic I was hoping for, so I concluded the YouTube algorithm is not promoting my content enough. I decided to investigate this and use my Data Science skills to solve the problem. In this blog post, I’ll share insights from my analysis and explore how YouTube’s algorithm impacts the visibility and success of dragonboat channels.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;exploring-channel-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploring Channel Data:&lt;/h2&gt;
&lt;p&gt;I started my analysis by going through the rabbit hole of searching for dragonboat content on videos, subscribing to channels, browsing my feed and repeating. In the end I collected 66 channels fully dedicated to the topic of dragonboat or even belonging to a specific team, and 29 channels which contained not just videos on paddling, but also other videos, similar to my channel. As far as country information for the channels was available, I gathered channels from around the world, with at least 11 from the US and Canada, 4 from Australia and New Zealand, at least 8 from South-East Asia (Taiwan, Philippines, Singapore, Indonesia) and at least 5 from Europe.&lt;br /&gt;
Using Python, I collected data on these channels as a starting point for further analysis on the contained videos (as for this we need the playlist ID for the channel uploads), but also to get aggregate view and subscriber counts, information on whether the channels have a channel trailer for unsubscribed visitors and how YouTube has categorised them.&lt;br /&gt;
Looking simply at aggregate view counts and the ratio of view count per video (to control for the fact that some channels are older than others), does not reveal that solely dragonboat-focussed channels generated more views than the channels with mixed content. There are channels of both types which have generated more than 100,000 views and on average more than 1,000 views per video, clearly outperforming my channel (at 21K views, i.e. 350 per video).&lt;br /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;views_by_channel_type_scatter.png&#34; alt=&#34;Figure 1 - aggregate views and views per video - log scale&#34; /&gt;&lt;br /&gt;
In terms of subscriber counts, three channels have surpassed and other three are close to the mark of 1,000 subscribers, which is one of the requirements for joining the YouTube partner program which allows you to generate ad revenue.&lt;br /&gt;
&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;the-impact-of-channel-categorization&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Impact of Channel Categorization:&lt;/h2&gt;
&lt;p&gt;Then, I decided to dig deeper into the issue of topic categories. In the analysis above I made the decision to group channels into ‘dragonboat’ and ‘mixed content’, but (how) does the YouTube algorithm categorize them?
Checking the frequencies of categories within the first three topic category lists of the channels reveals that most ‘mixed content’ channels in my sample are categorized similarly to the pure ‘dragonboat’ channels, having as first category ‘Sports’, as second category ‘Lifestyle’ and as third category - if available - ‘Vehicle’ (for boat).&lt;br /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;topic_categories_db.png&#34; alt=&#34;Figure 2 - Topic categories for dragonboat channels&#34; /&gt;&lt;br /&gt;
&lt;img src=&#34;topic_categories_mixed.png&#34; alt=&#34;Figure 3 - Topic categories for mixed content channels&#34; /&gt;&lt;br /&gt;
&lt;/p&gt;
&lt;p&gt;By contrast, the topic categories returned for &lt;a href=&#34;https://www.youtube.com/@AlexMelemenidis&#34;&gt;my channel&lt;/a&gt; are:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Hobby&lt;/li&gt;
&lt;li&gt;Sport&lt;/li&gt;
&lt;li&gt;Tourism&lt;/li&gt;
&lt;li&gt;Lifestyle&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So it seems that I am more mixed than these mixed channels. On my channel I also feature travel videos and some pure aerial content drone videos, which appears to confuse the algorithm when deciding which content to show on a user’s feed.&lt;/p&gt;
&lt;p&gt;Professional YouTuber also advise to have &lt;strong&gt;consistent content&lt;/strong&gt; in one channel. Besides the categorization, the YouTube algorithm also promotes the content of channel based on its &lt;strong&gt;previous success&lt;/strong&gt; in terms of the count of viewers and subscribers, how many users click on impressions of a video in their feed (the so-called ‘click-through-rate’) and how long the viewers are actually watching the video (‘retention’).
While I personally like &lt;a href=&#34;https://www.youtube.com/playlist?list=PLpW2X6ap8IsVrZQt3HgyLb89igcNMOxit&#34;&gt;paddling&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/playlist?list=PLpW2X6ap8IsUq_5SPBWske4rQgJsC3A1X&#34;&gt;surfing&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/playlist?list=PLpW2X6ap8IsXzPVj5rfYpwAJDdkImVqGd&#34;&gt;skiing&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/playlist?list=PLpW2X6ap8IsV4s9P7-EXgnCMmQLG0GakE&#34;&gt;travelling&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/playlist?list=PLpW2X6ap8IsUITs2rTHvWMl_jmNlbMpz6&#34;&gt;obstacle course racing&lt;/a&gt;, hiking and &lt;a href=&#34;https://www.youtube.com/playlist?list=PLpW2X6ap8IsVINEBJPJrKqgFQ_GYhpVmt&#34;&gt;flying drones&lt;/a&gt;, other people may not necessarily like &lt;strong&gt;all of these activities together&lt;/strong&gt;. So someone who has seen and liked my ski-trip videos will be shown my dragonboat videos in their feed, but will not be interested and thus reduce my click-through rate, or click and then stop the video after a few seconds, hurting my retention rate.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/ow2gIOxZCN0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;
Besides the topic categories, I looked into another component of channels: some channels greet unsubscribed new viewers on their channel page with a channel trailer that introduces what the channel is about and raises a call to action to subscribe. As in the public data API I cannot retrieve historical information, I can only check if there is a correlation between the existence of a trailer and the subscriber count. So it might be that as channels have gained more subscribers, they later took the time to add a channel trailer, rather than the trailer nudging more users to click subscribe, but the correlation nonetheless looks quite strong. So it might be a good idea for me to add a channel trailer, as currently I don’t have one.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;channel_trailer_boxplot.png&#34; alt=&#34;Figure 4 - Distribution of subscriber count by whether there is a channel trailer&#34; /&gt;&lt;br /&gt;
&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;insights-from-video-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Insights from Video Data:&lt;/h2&gt;
&lt;p&gt;Further investigation into individual videos uncovered valuable insights. Both groups of channels contained around 10,000 videos, on which I could retrieve useful statistics on views, likes, shares, as well as information on their descriptions, or the duration of the video.
Looking at individual videos, it seems that videos from dragonboat channels somewhat outperform those from mixed-content channels in terms of views and likes.
&lt;img src=&#34;videos_likes_vs_views_scatter.png&#34; alt=&#34;Figure 5 - View count vs Like count by channel type - Log scale&#34; /&gt;
Additionally, the presence of hashtags and descriptive content in video descriptions positively correlated with view counts, indicating their importance in attracting viewership. Since the YouTube algorithms has been changed over the years and the use of hashtags is also quite recent, I restricted that analysis to only videos published since 2022. In both cases the inter-quartile range of the video views ranges much higher if the video has a description and higher if the description contains hashtags for search.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;hashtags_boxplot.png&#34; alt=&#34;Figure 6 - Distribution of video view count by whether the description contains hashtags&#34; /&gt;
&lt;img src=&#34;non_empty_description_boxplot.png&#34; alt=&#34;Figure 7 - Distribution of video view count by whether the description contains any text&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Lastly, I analyzed whether viewers of dragonboat videos prefer videos of a certain duration, as mine are often on the longer side, especially for those showing international trips with some travel content at the beginning.&lt;/p&gt;
&lt;p&gt;For both views and likes there does not appear to be any siginficant correlation with the duration of the video, but all in all there is a sweet spot in which most of the videos simply are, with the middle 50% of videos being in the range of one to three minutes long.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;videos_views_vs_duration_scatter.png&#34; alt=&#34;Figure 8 - View count vs. duration (seconds) by channel type - log scale&#34; /&gt;&lt;br /&gt;
&lt;img src=&#34;videos_likes_vs_duration_scatter.png&#34; alt=&#34;Figure 9 - Like count vs. duration (seconds) by channel type - log scale&#34; /&gt;&lt;br /&gt;
&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;monitoring-my-own-channel-using-the-youtube-analytics-api&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Monitoring my own channel using the YouTube Analytics API:&lt;/h2&gt;
&lt;p&gt;Already some months ago I started becoming more interested in the issue and asked ChatGPT to improve my video descriptions in terms of search engine optimization (SEO). For some videos that did not yet have custom thumbnails I also added them. These changes occurred around the 18th of February 2024 so I wanted to check on the YouTube Analytics API whether this had an effect. Unfortunately the metric of ‘Annotation Impressions’ - the presentation of a clickable thumbnail to a video in a user’s feed, which is visible without a problem in the YouTube Studio App, cannot be retrieved via the API. In terms of overall views for these older videos with improved descriptions and thumbnails the effect appears still marginal, but I will keep an eye on the developments.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;analytics_adjustment_seo.png&#34; alt=&#34;Figure 10 - View Count over time for videos with adjusted metadata&#34; /&gt;&lt;br /&gt;
&lt;/p&gt;
&lt;p&gt;Annotation impressions for all my videos did increase when I made the changes in titles, descriptions and thumbnails (third spike), but this could still have been boosted by the prior publication of two other videos (previous two spikes).&lt;/p&gt;
&lt;div class=&#34;float&#34;&gt;
&lt;img src=&#34;Screenshot_YT_Studio.jpg&#34; alt=&#34;Figure 11 - Aggregate annotation impressions&#34; /&gt;
&lt;div class=&#34;figcaption&#34;&gt;Figure 11 - Aggregate annotation impressions&lt;/div&gt;
&lt;/div&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;my-learnings&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;My learnings:&lt;/h2&gt;
&lt;p&gt;In conclusion, my analysis offers valuable insights into the complexities of YouTube’s algorithm and its impact on content visibility.
Moving forward, I aim to leverage these insights to refine my content strategy and enhance the overall viewing experience for dragonboat enthusiasts worldwide.&lt;br /&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Most importantly this means that I will publish new content on &lt;strong&gt;dedicated channels&lt;/strong&gt; aligning with the YouTube topic categories. For this I have already created a new dragonboat channel for my team &lt;a href=&#34;https://www.youtube.com/@FFM-Mixup-DB&#34;&gt;Frankforter Dorschenanner&lt;/a&gt; ✅. So far I will keep the existing videos on the old channel, as the migration of videos will reset the views and likes and I am not yet willing to do that.&lt;/li&gt;
&lt;li&gt;I will try to shoot a little channel trailer 🎥 and make sure descriptions and titles are search-optimized and thumbnails exciting enough to make people click!&lt;/li&gt;
&lt;li&gt;In particular for typical dragonboat regattas with multiple races, I will create separate ‘raw’ videos for each race, as this aligns better with the length viewers are used to rather than one longer video with chapters. Also, this strategy helps my statistics for becoming a YouTube partner, as one should publish at least three videos in the last 90 days.&lt;br /&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let’s make 2024 viral! 🤩&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>My trial-and-error journey of creating AI art of myself using Open Source models and tools</title>
      <link>https://alex.melemenidis.de/post/2024-03-11-trial-and-error-journey-of-ai-art/</link>
      <pubDate>Mon, 11 Mar 2024 00:00:00 +0000</pubDate>
      
      <guid>https://alex.melemenidis.de/post/2024-03-11-trial-and-error-journey-of-ai-art/</guid>
      <description>


&lt;p&gt;&lt;em&gt;Caveat: You need a computer with a graphics card with a GPU and at least 8GB VRAM. If not you can at least profit from the code-based part in Google Colab.&lt;/em&gt;&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Generative AI has taken the world by storm, opening up new realms of creativity and innovation. From chatbots powered by large language models (LLMs) to text-to-image models like Stable Diffusion, the possibilities seem boundless. The allure of AI in the art world has captivated enthusiasts, offering a unique blend of technology and creativity. In this blog post, I’ll share my journey of creating AI art of myself using open source models and tools, such as Stable Diffusion, Dreambooth, and the user-friendly GUI-based tool “Automatic1111.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-catalyst-a-black-friday-gaming-pc&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Catalyst: A Black Friday Gaming PC&lt;/h2&gt;
&lt;p&gt;Last Black Friday, I decided invest in a &lt;a href=&#34;https://support.hp.com/de-de/product/details/omen-by-hp-25l-gaming-desktop-pc-gt15-1000i/model/2101441844?sku=8R2T0EA&#34;&gt;gaming desktop&lt;/a&gt; equipped with a powerful GPU, initially to improve my video editing workflow (which can already be witnessed in my recent &lt;a href=&#34;https://youtu.be/YXaXeL5XsDE&#34;&gt;Thailand travel video&lt;/a&gt;). But one other reason for the investment was that I also wanted to take the plunge into the world of generative AI and be able to test these powerful models locally.This decision was driven by the desire to explore the creative potential of AI models and algorithms, especially those designed for transforming images and generating unique pieces of digital art.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;learning-the-ropes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Learning the Ropes&lt;/h2&gt;
&lt;p&gt;Armed with my new gaming desktop, I embarked on a journey of self-discovery through various Udemy courses dedicated to generative AI. In terms of text-to-image models I followed the course &lt;a href=&#34;https://www.udemy.com/course/master-ai-image-generation-using-stable-diffusion/?kw=Master+AI+Image&amp;amp;src=sac&#34;&gt;Master AI image generation using Stable Diffusion&lt;/a&gt; which gave a good overview and had excellent Google Colab notebooks with example implementations.
The course provided me with a foundational understanding of the tools and techniques involved in using GenAI. At the time, however, I was still busy with work and looking for a new job so that I could not find sufficient time to test these tools on my new PC.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;overcoming-hurdles&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Overcoming Hurdles&lt;/h2&gt;
&lt;p&gt;When I came back to the topic, I wanted to play with image generation models using a graphical user interface (GUI) tool rather than code, since creating these images involves a lot of trial and error and changing settings and that works much better using GUI-based tools with buttons and sliders than adjusting code snippets all the time. On YouTube I stumbled over discussions on &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;&gt;Automatic1111&lt;/a&gt; and how to also use Dreambooth to finetune an existing model on new images.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/3cvP7yJotUM&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;
&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/9Nu5tUl2zQw&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;
The initial stages of my exploration were not without their share of hurdles. Wrestling with Python dependencies and configuring the right settings proved to be a daunting task. It took me a while to get things running, in particular installing the &lt;code&gt;xformers&lt;/code&gt; package and needed a few trips through Google &amp;amp; StackOverflow to get it to work (and unfortunately have forgotten by now what was the trick 😅), but finally succeeded.&lt;/p&gt;
&lt;p&gt;Then I checked out some popular video tutorials by &lt;a href=&#34;https://www.youtube.com/@OlivioSarikas&#34;&gt;Olivio Sarikas&lt;/a&gt; and &lt;a href=&#34;https://www.youtube.com/@SECourses&#34;&gt;Dr. Furkan Gözükara&lt;/a&gt;, which helped explaining the menus and settings and the general process to use the Dreambooth extension.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/Bdl-jWR3Ukc&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;
However, since the videos were produced, Automatic1111 was updated, with changes to the menus and often also to the default options for many settings, making it more difficult to reproduce the results shown in the videos. While I managed to create some interesting pictures using the text-to-image functionality of the models, I was not really able to fine-tune a model to my face, either because the results looked bad or because the process would simply take too long on my system with only 8GB available with my GPU.&lt;br /&gt;
So only recently I took another go at it and remembered that refining with Dreambooth was also featured in the Udemy course I did last year, and revisited the Google Colab notebook to re-run it with my own training data.&lt;br /&gt;
Have a look into &lt;a href=&#34;https://colab.research.google.com/drive/1jeuzMNWOHys_ciWzOj78daTBmJuqkxAO?usp=sharing&#34;&gt;&lt;strong&gt;my adjusted copy of that notebook&lt;/strong&gt;&lt;/a&gt;. There you can fine-tune the StableDiffusion 1.5 model (or any other model available on &lt;a href=&#34;https://huggingface.co/models?pipeline_tag=text-to-image&amp;amp;sort=trending&#34;&gt;HuggingFace&lt;/a&gt;) with your own data. To bring your images in the right format you can use the web tool &lt;a href=&#34;https://www.birme.net/?target_width=512&amp;amp;target_height=512&#34;&gt;BIRME&lt;/a&gt;, which can resize your images in bulk and already select a good focal point (where the image format is not already square). Then you can also copy the created model checkpoint into your Google Drive to later download it to your local machine and use it in Automatic1111.&lt;br /&gt;
One additional step is needed before using the downloaded model locally, which is converting the .ckpt file into a .safetensors file, otherwise Automatic1111 will throw an error, at least it did for me. I used the &lt;a href=&#34;https://github.com/diStyApps/Safe-and-Stable-Ckpt2Safetensors-Conversion-Tool-GUI&#34;&gt;Ckpt2Safetensors Conversion Tool&lt;/a&gt; to perform the conversion.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-breakthrough-creating-impressive-ai-art&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Breakthrough: Creating Impressive AI Art&lt;/h2&gt;
&lt;p&gt;After navigating the intricacies of generative AI, I finally achieved a breakthrough, producing impressive AI art of myself using Stable Diffusion, Dreambooth, and the intuitive GUI-based tool “Automatic1111.” The amalgamation of these open source models and tools allowed me to transcend traditional boundaries and explore the endless possibilities of self-expression through artificial intelligence.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;00011-2157247297.png&#34; style=&#34;width:40.0%&#34; alt=&#34;Prompt: illustration of ohwx man, like obama yes we can poster, realistic, blue and red&#34; /&gt; &lt;img src=&#34;00017-4088469429.png&#34; style=&#34;width:40.0%&#34; alt=&#34;Prompt: (ohwx man) as the simpsons character, glasses&#34; /&gt; 
&lt;img src=&#34;00031-4033097712.png&#34; style=&#34;width:40.0%&#34; alt=&#34;Prompt: 2x2 grid of portraits of (ohwx man), popart by Andy Warhol&#34; /&gt; &lt;img src=&#34;00030-1322871741.png&#34; style=&#34;width:40.0%&#34; alt=&#34;(ohwx man) as muppet show character&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Learnings so far:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As described in the other tutorials, you should &lt;strong&gt;pay attention to your training data&lt;/strong&gt; having enough variation in terms of &lt;em&gt;angles, lighting, clothing and facial expression&lt;/em&gt;. So in case you don’t have enough make some “selfies” looking to the side, up etc. Following the video tutorials suggestions I included mostly pictures of me that were from close enough, around from the waist up. However, what I witness in almost all generated images with the generated “me” being smaller and further away is that the face is messed up. So I wonder if this can improve with more images of me being at a higher distance and will try to re-train. But it could also be that this is a general feature of finetuning at lower resolutions (512x512 pixels) and these pictures need to be refined later anyways.&lt;/li&gt;
&lt;li&gt;Pay attention to your &lt;strong&gt;prompts&lt;/strong&gt;, make them as detailed as possible and also use negative prompts. There are many websites that give some inspiration for good prompts (e.g. &lt;a href=&#34;https://stable-diffusion-art.com/prompt-guide/&#34;&gt;here&lt;/a&gt;), and the Automatic1111 extension “Prompt Generator” is very useful to create some more ideas.&lt;/li&gt;
&lt;li&gt;Google Colab in the free version is actually not that powerful. During the training process the T4 GPU always used less than 8GB VRAM, which is also what I would have available locally with my GeForce GTX 4070Ti. So I wonder if the issue was simply the different settings. I downloaded the generated .json-files containing the finetuning parameters, so I will try to test these locally again.&lt;/li&gt;
&lt;li&gt;Play around again and again, also testing different settings. The “X/Y/Z” Script functionality can be a useful tool to test different values for the paramters “CFG Scale”, “Scheduler” or simply different random seeds. It might be a good idea to generate a larger batch of images using one CFG value, then take the seeds of the pictures you like and then create image grids with different values of CFG Scale to further refine.&lt;/li&gt;
&lt;li&gt;There is still so much more to explore! Additional models, like ControlNets are able to fix common issues like misformed faces or hands (with extra fingers), or upscale the images to higher resolutions.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion:&lt;/h2&gt;
&lt;p&gt;My journey into the world of generative AI art has been a rollercoaster of challenges and triumphs. From acquiring a gaming PC on Black Friday to navigating the complexities of Python and software updates, the experience has been both educational and rewarding. Through perseverance and dedication, I’ve not only learned to harness the power of AI for artistic expression but have also witnessed the transformative potential of these open source models and tools. As the realm of generative AI continues to evolve, so too does the canvas of possibilities for creative individuals eager to explore the intersection of technology and art.&lt;br /&gt;
&lt;br /&gt;
&lt;em&gt;Note: this blog post was co-authored by ChatGPT (GPT 3.5 Turbo), so also expect some post in the near future on LLMs! ;-)&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>pro-bono project at Deloitte - Wildlife conservation with AI and Cloud technologies</title>
      <link>https://alex.melemenidis.de/post/2023-10-15-wildlife-conservation-with-ai/</link>
      <pubDate>Sun, 15 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>https://alex.melemenidis.de/post/2023-10-15-wildlife-conservation-with-ai/</guid>
      <description>


&lt;div id=&#34;deloittes-biodiversity-dashboard-lays-the-groundwork-for-data-driven-community-based-conservation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Deloitte’s Biodiversity Dashboard lays the groundwork for data-driven community-based conservation&lt;/h2&gt;
&lt;p&gt;During my tenure at Deloitte I was so lucky to be leading a small project team working with a large environmental NGO on a pro-bono basis.&lt;/p&gt;
&lt;p&gt;The project premise was the following:&lt;/p&gt;
&lt;p&gt;Since Namibia’s independence in the 1990s, wildlife conservation followed a community-driven approach. Rural communities can declare themselves ‘Communal Conservancies’, a special legal entity with specifically defined geographic boundaries. With this legal status, communities have to commit to specific nature conservation targets and be monitored against them by the government or authorised actors (such as this NGO). In turn they considered sole leaseholders of the land, are allowed to create Safari lodges, heritage villages and allow hunting (in line with quotas) and can keep all profits from tourism for themselves.
With the introduction of the concept the populations of many endangered species in Namibia recovered and the buy-in of communities was strong, with now 86 registered communal conservancies by 2024, covering around 20.2% of the country according to the Association of organisations supporting communities, &lt;a href=&#34;https://www.nacso.org.na/&#34;&gt;NACSO&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;During the Covid-19 pandemic, however, the concept showed its weaknesses due to the reliance on tourism income. Without being able to support their livelihoods, communities were more likely to decrease their efforts of conserving flora and fauna.
To provide an additional income source, the client introduced a new program, paying communities directly from donations and development banks for additional &lt;strong&gt;efforts that can be validated by data&lt;/strong&gt;.&lt;br /&gt;
The communities and the NGO signed additional contracts relating to specific parts of the community land that should remain free of human interference. Namely, the communities had to record regular ranger surveys into these parcels using a smartphone app, documenting the GPS routes as well as any observations made along the way. Second, communities had to should deploy &lt;strong&gt;camera traps&lt;/strong&gt; to monitor the presence of endangered species. We were then tasked to combine and process this data in a most efficient way to determine whether communities were compliant.&lt;/p&gt;
&lt;div class=&#34;float&#34;&gt;
&lt;img src=&#34;furkanvari-PRo3VY-PKBE-unsplash.jpg&#34; alt=&#34;A camera trap; Photo by furkanvari on Unsplash&#34; /&gt;
&lt;div class=&#34;figcaption&#34;&gt;A camera trap; Photo by furkanvari on Unsplash&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;
We implemented this as a cloud-based solution in AWS, harnessing computer vision models and a business intelligence solution with some custom add-ons.
We also added as a third data source freely available &lt;strong&gt;remote sensing imagery&lt;/strong&gt; from the ESA Sentinel missions, to exclude signs of fire-clearing on the specially designated land.&lt;/p&gt;
&lt;div class=&#34;float&#34;&gt;
&lt;img src=&#34;usgs-_HZo1HuTb2s-unsplash.jpg&#34; alt=&#34;Remote sensing imagery; Photo by USGS on Unsplash&#34; /&gt;
&lt;div class=&#34;figcaption&#34;&gt;Remote sensing imagery; Photo by USGS on Unsplash&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;
Check out the short demo video showing the solution we built.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/YAQmwfZ7i2I&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;
Read the &lt;a href=&#34;https://www2.deloitte.com/de/de/pages/risk/solutions/effective-wildlife-conservation-with-biodiversity-dashboard.html&#34;&gt;short article&lt;/a&gt; on the Deloitte aiStudio website for more information.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The semiconductor shortage and its implication for euro area trade, production and prices</title>
      <link>https://alex.melemenidis.de/publication/ecbu-semiconductor/</link>
      <pubDate>Thu, 24 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://alex.melemenidis.de/publication/ecbu-semiconductor/</guid>
      <description></description>
    </item>
    
    <item>
      <title>How to web-scrape data from multiple pages</title>
      <link>https://alex.melemenidis.de/post/2021-02-10-tutorial-webscraping/</link>
      <pubDate>Wed, 10 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://alex.melemenidis.de/post/2021-02-10-tutorial-webscraping/</guid>
      <description>
&lt;script src=&#34;https://alex.melemenidis.de/post/2021-02-10-tutorial-webscraping/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Through my involvement in &lt;a href=&#34;https://correlaid.org/correlaid-x/rhein-main/&#34;&gt;Correlaid Rhein-Main&lt;/a&gt; I received a license to &lt;a href=&#34;https://www.dataquest.io/&#34;&gt;Dataquest&lt;/a&gt; so I took the opportunity to learn some new tricks! While I skipped most of the beginner classes of the “Data Analyst in R” path, I thought the two courses on &lt;a href=&#34;https://app.dataquest.io/course/apis-in-r&#34;&gt;APIs&lt;/a&gt; and &lt;a href=&#34;https://app.dataquest.io/course/scraping-in-r&#34;&gt;web-scraping&lt;/a&gt; might be useful: so far my use of APIs at work mostly was done via packages (or, as in the Bee Observer project, prepared by somebody else), so I was interested to know what’s behind these &lt;code&gt;GET&lt;/code&gt; and &lt;code&gt;POST&lt;/code&gt; commands. While I still had some good learning experiences, I still had the impression that the course had some teething problems and many things were not well explained or described. I will still try to share my comments with the course developers so that hopefully they will improve it for future users - I had done so already via the community page, but apparently this was not the right place… 😒&lt;br /&gt;
Anyhow… the web-scraping course was luckily much better in my opinion! 😃&lt;br /&gt;
It teaches well how to use the &lt;code&gt;rvest&lt;/code&gt; package and search for the right html selectors using the inspect tool of your web browser and the &lt;a href=&#34;https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb?hl=de&#34;&gt;selector gadget&lt;/a&gt; for Google Chrome. After that I wanted to immediately jump in and find use-cases at work to implement my new knowledge. One task that came to mind is rather dull and administrative - and thus even more so a good candidate for automation. Within the process of the &lt;a href=&#34;https://www.ecb.europa.eu/pub/projections/html/index.en.html&#34;&gt;macroeconomic projection exercises&lt;/a&gt; the special team coordinating the exercises circulates well in advance of the next projection round a propose calendar outlining the timeline of forecast iterations and high-level meetings. Building on top of this general FTF (Forecast Task Force) calendar, my division, responsible for the projections for the largest five euro area countries, creates another one with more intermediate steps that are relevant for the country experts producing the forecast hands-on. As a guide for when might be the right time to work on the forecast we also enter in this calendar a column with the release dates of important macroeconomic indicators. For a long time this was a rather manual job, which could cost you a few hours to get all the data ready, oftentimes in an otherwise busy period.
The statistical offices &lt;a href=&#34;https://ec.europa.eu/eurostat/web/main/news/internet-calendar&#34;&gt;Eurostat&lt;/a&gt;, &lt;a href=&#34;https://www.istat.it/en/information-and-services/journalists/release-calendar/press-room-calendar&#34;&gt;Istat&lt;/a&gt; and &lt;a href=&#34;https://ine.es/en/daco/daco41/calen_ics_en.htm&#34;&gt;INE&lt;/a&gt; all offer internet calendars, which can be imported to Outlook, but also be read using the &lt;code&gt;calendar&lt;/code&gt; package. The national statistical offices of the Netherlands (&lt;a href=&#34;https://www.cbs.nl/&#34;&gt;CBS&lt;/a&gt;) and Germany (&lt;a href=&#34;https://www.destatis.de/DE/Home/_inhalt.html&#34;&gt;Destatis&lt;/a&gt;), howevever, only offer their release dates as lists or tables on the website.
The &lt;a href=&#34;https://www.destatis.de/SiteGlobals/Forms/Suche/Termine/EN/Terminsuche_Formular.html&#34;&gt;annual calendar of Destatis&lt;/a&gt; is in particular tricky, because the list is split over multiple pages.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;images/destatis_1.png&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;page content split over multiple pages accessible via navigation buttons&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;But let’s get to that part later. First let’s just find the selector for the data releases. Using the inspect tool of the browser we see that the items we are interested in are contained within the a div of class &lt;code&gt;row&lt;/code&gt; within a div of class &lt;code&gt;c-result&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;images/destatis_2.png&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;css selector for the required data&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Now let’s start getting our hands dirty in R and load the &lt;code&gt;rvest&lt;/code&gt; and &lt;code&gt;tidyverse&lt;/code&gt; packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rvest)
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see what the output of the first page looks like. For that we use &lt;code&gt;read_html&lt;/code&gt; on the URL of the first page, select the nodes as identified above using &lt;code&gt;html_nodes&lt;/code&gt; and convert to text using &lt;code&gt;html_text&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;destatis_calendar_first &amp;lt;- read_html(
  &amp;quot;https://www.destatis.de/SiteGlobals/Forms/Suche/Termine/EN/Terminsuche_Formular.html&amp;quot;
) %&amp;gt;% 
  html_nodes(&amp;quot;.c-result .row&amp;quot;) %&amp;gt;% 
  html_text()

destatis_calendar_first&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;\n    \n      Persons employed in manufacturing\n      Reporting period: December 2020\n        Date of issue: 2021.02.16  (deadline)\n      \n  &amp;quot;                         
##  [2] &amp;quot;\n    \n      Indices of wholesale trade prices\n      Reporting period: January 2021\n        Date of issue: 2021.02.17  (deadline)\n      \n  &amp;quot;                          
##  [3] &amp;quot;\n    \n      Indices of the stock of orders and ranges in manufacturing\n      Reporting period: December 2020\n        Date of issue: 2021.02.18\n      \n  &amp;quot;            
##  [4] &amp;quot;\n    \n      Quarterly labour market statistics\n      Detailed breakdown\n\n      Reporting period: 4th quarter 2020\n        Date of issue: 2021.02.18\n      \n  &amp;quot;     
##  [5] &amp;quot;\n    \n      Insolvencies\n      Reporting period: November 2020\n        Date of issue: 2021.02.19  (deadline)\n      \n  &amp;quot;                                              
##  [6] &amp;quot;\n    \n      Producer price index of industrial products\n      Reporting period: January 2021\n        Date of issue: 2021.02.19\n      \n  &amp;quot;                            
##  [7] &amp;quot;\n    \n      Gross domestic product \n      Detailed breakdown\n\n      Reporting period: 4th quarter 2020\n        Date of issue: 2021.02.24\n      \n  &amp;quot;                
##  [8] &amp;quot;\n    \n      Maastricht deficit ratio\n      Reporting period: Year 2020\n        Date of issue: 2021.02.24\n      \n  &amp;quot;                                                  
##  [9] &amp;quot;\n    \n      Index of orders received\n      provisional release date\n\n      Reporting period: December 2020\n        Date of issue: 2021.02.25  (deadline)\n      \n  &amp;quot;
## [10] &amp;quot;\n    \n      Traffic accident\n      Reporting period: December 2020\n        Date of issue: 2021.02.25  (deadline)\n      \n  &amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This output still has some issues that should be fixed, like the abundance of line breaks and whitespace, but we can leave this for later. The fact that we have a character vector of length 10 is already going in the direction that we want.&lt;/p&gt;
&lt;p&gt;Now the question is how we can get to the next pages programatically. For this we will inspect the “next” arrow at the bottom of the page.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;images/destatis_3.png&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;html attribute of the navigation button&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;We see that the forward button is an element with the class &lt;code&gt;forward button&lt;/code&gt; and has as an &lt;code&gt;href&lt;/code&gt; attribute the URL of the next page, however as a relative address (i.e. without the base URL). If you would check on the last possible page of the list, you can see that the (now greyed out) forward button now does not contain an href attribute.&lt;/p&gt;
&lt;p&gt;So we can define a loop that starts on the first page, reads the data as well as the URL of the following page from the forward button (using &lt;code&gt;html_attr(&#34;href&#34;)&lt;/code&gt;) and then updates the page from which to read. This loop is repeated (with the data appended to the previously scraped data) until the last page is reached where the aforementioned command will return a missing value.
As discussed before, the content of the rows is a little problematic due to line breaks and spaces, but otherwise is quite structured. Using some string operations and regular expressions we can split the information into three columns, containing the name of the indicator, the reference period of the data release, and the release date.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;base_url &amp;lt;- &amp;quot;https://www.destatis.de/&amp;quot;

destatis_calendar &amp;lt;- read_html(
  &amp;quot;https://www.destatis.de/SiteGlobals/Forms/Suche/Termine/EN/Terminsuche_Formular.html&amp;quot;
) 

current_page &amp;lt;- destatis_calendar
next_endpoint &amp;lt;- destatis_calendar %&amp;gt;% 
  html_node(&amp;quot;li .forward.button&amp;quot;) %&amp;gt;% 
  html_attr(&amp;quot;href&amp;quot;)

entries &amp;lt;- tibble(indicator = character(), 
                  reference_period = character(), 
                  release = character())

repeat{
  current_entries &amp;lt;- current_page %&amp;gt;% 
    html_nodes(&amp;quot;.c-result&amp;quot;) %&amp;gt;% 
    # I need to get to the second level div
    html_nodes(&amp;quot;div div&amp;quot;) %&amp;gt;% 
    html_text() %&amp;gt;% trimws() %&amp;gt;%
    as_tibble() %&amp;gt;%
    extract(value, into = c(&amp;quot;indicator&amp;quot;, &amp;quot;reference_period&amp;quot;, &amp;quot;release&amp;quot;),
            regex = &amp;quot;^(.*\\s.*)\\s*Reporting period:(.*)\\s*Date of issue: (\\d{4}.\\d{2}\\.\\d{2})&amp;quot;)
  # I need to use the general whitespace character \s as the normal linebreak \n somehow didn`t work.
  
  entries &amp;lt;- union(entries, current_entries)
  
  next_endpoint &amp;lt;- current_page %&amp;gt;% 
    html_node(&amp;quot;li .forward.button&amp;quot;) %&amp;gt;% 
    html_attr(&amp;quot;href&amp;quot;)
  
  if(is.na(next_endpoint)) break # break the loop if we are on the last page

  # update page by following the forward button
  current_page &amp;lt;- read_html(paste0(base_url, next_endpoint))
}

rm(current_page, current_entries, next_endpoint)

destatis_releases &amp;lt;- entries %&amp;gt;% 
  mutate(release = as.Date(release, &amp;quot;%Y.%m.%d&amp;quot;),
         indicator = trimws(indicator))

head(destatis_releases)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
##   indicator                                        reference_period   release   
##   &amp;lt;chr&amp;gt;                                            &amp;lt;chr&amp;gt;              &amp;lt;date&amp;gt;    
## 1 &amp;quot;Persons employed in manufacturing&amp;quot;              &amp;quot; December 2020&amp;quot;   2021-02-16
## 2 &amp;quot;Indices of wholesale trade prices&amp;quot;              &amp;quot; January 2021&amp;quot;    2021-02-17
## 3 &amp;quot;Indices of the stock of orders and ranges in m~ &amp;quot; December 2020&amp;quot;   2021-02-18
## 4 &amp;quot;Quarterly labour market statistics\n      Deta~ &amp;quot; 4th quarter 202~ 2021-02-18
## 5 &amp;quot;Insolvencies&amp;quot;                                   &amp;quot; November 2020&amp;quot;   2021-02-19
## 6 &amp;quot;Producer price index of industrial products&amp;quot;    &amp;quot; January 2021&amp;quot;    2021-02-19&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I hope you found this tutorial useful!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Unsupervised Anomaly Detection on Multisensory Data from Honey Bee Colonies</title>
      <link>https://alex.melemenidis.de/publication/bee-anomaly/</link>
      <pubDate>Tue, 09 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://alex.melemenidis.de/publication/bee-anomaly/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The ECB Corporate Telephone Survey (CTS)</title>
      <link>https://alex.melemenidis.de/post/2021-02-07-the-ecb-cts/</link>
      <pubDate>Sun, 07 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://alex.melemenidis.de/post/2021-02-07-the-ecb-cts/</guid>
      <description>
&lt;script src=&#34;https://alex.melemenidis.de/post/2021-02-07-the-ecb-cts/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Things had already been moving in the right direction in the recent years: for a number of years our annual written special surveys, making use of our CTS contacts, had been published in the Economic Bulletin, exploring the views of the non-financial corporate sector on various topics such as &lt;a href=&#34;https://www.ecb.europa.eu/pub/economic-bulletin/html/eb201606.en.html#IDofChapter2_4&#34;&gt;trade patterns and global value chains (2016)&lt;/a&gt;, &lt;a href=&#34;https://www.ecb.europa.eu/pub/economic-bulletin/html/eb201706.en.html#IDofBox5&#34;&gt;structural reform needs (2017)&lt;/a&gt;, &lt;a href=&#34;https://www.ecb.europa.eu/pub/economic-bulletin/focus/2018/html/ecb.ebbox201807_04.en.html&#34;&gt;digitalisation (2018)&lt;/a&gt;, &lt;a href=&#34;https://www.ecb.europa.eu/pub/economic-bulletin/focus/2019/html/ecb.ebbox201907_04~1d48c6bf77.en.html&#34;&gt;price setting behaviour (2019)&lt;/a&gt;, and lastly the &lt;a href=&#34;https://www.ecb.europa.eu/pub/economic-bulletin/focus/2021/html/ecb.ebbox202008_06~bad87fcf9b.en.html&#34;&gt;long-term effects of the Covid-19 pandemic (2021)&lt;/a&gt;.&lt;br /&gt;
Likewise, in line with the new &lt;a href=&#34;https://www.ecb.europa.eu/ecb/orga/transparency/html/eb-communications-guidelines.en.html&#34;&gt;transparency guidelines&lt;/a&gt;, the annual meetings of the ECB Governing Council with selected high-level representatives of our surveyed companies has been part of the public calendar as the &lt;a href=&#34;https://www.ecb.europa.eu/mopo/devel/html/nfbd.en.html&#34;&gt;Non-Financial Business Sector Dialogue (NFBD)&lt;/a&gt;.&lt;br /&gt;
So far, however, outside observers would not know how these contacts with stakeholders of the real economy were established in the first place. This was now cleared up with the publication of an &lt;a href=&#34;https://www.ecb.europa.eu/pub/economic-bulletin/articles/2021/html/ecb.ebart202101_01~2760392b32.en.html&#34;&gt;article and a box&lt;/a&gt; in the Economic Bulletin Issue 1/2021:
every quarter a small team of ECB staff is contacting a small sample of large non-financial corporations active across the Euro area in order to gain insights in to the current state of the business cycle in their sector, i.e. in the last quarter, their expectations for the current quarter and what factors are behind these developments. This is an extremely interesting project, which also forces interviewers to familiarise themselves with sector-topical issues, to be well prepared for the short phone interviews with our busy counterparts, often high-level executives such as the CFO.&lt;/p&gt;
&lt;p&gt;I am personally involved in the teams dealing with two sectors:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;transport and logistics services, which includes operators of infrastructure such as ports, airports and motorways, and service providers such as airlines, shipping companies and providers of supply-chain logistics solutions&lt;/li&gt;
&lt;li&gt;intermediate goods manufacturing, which includes producers of basic metals, chemicals, packaging solutions and more elaborate components further used in other industries.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I am very happy that this work, which provides important information feeding in to the ECB’s monetary policy, is finally publicly acknowledged.
For more information, read the article and box on the ECB website &lt;a href=&#34;https://www.ecb.europa.eu/pub/economic-bulletin/articles/2021/html/ecb.ebart202101_01~2760392b32.en.html&#34;&gt;HERE&lt;/a&gt;!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lockdown productivity</title>
      <link>https://alex.melemenidis.de/post/2021-01-10-lockdown-productivity/</link>
      <pubDate>Sun, 10 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://alex.melemenidis.de/post/2021-01-10-lockdown-productivity/</guid>
      <description>


&lt;p&gt;Happy New Year everyone!&lt;/p&gt;
&lt;p&gt;The last holiday period under Covid-19 restrictions was certainly different than in other, normal years. On the one hand I had more time available, as I consumed unused leave days before they would expire, but at the same time I could not meet my old hometown friends as often as I wanted or go to the fantastic christmas market of Braunschweig, which is normally a highlight of the holidays. So I restricted myself to one outside meetup with my friends for a walk in the park, otherwise played UNO or Yahtzee with my parents, my brother and his girlfriend and otherwise spent my time digitally to stay productive and creative.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;I learned to use &lt;code&gt;blogdown&lt;/code&gt; to build this very personal homepage from the awesome &lt;a href=&#34;https://bookdown.org/yihui/blogdown/&#34;&gt;book by Yihui Xie&lt;/a&gt;.&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;I freshened up my knowledge of &lt;code&gt;shiny&lt;/code&gt;, as this might come in handy at work soon. The book &lt;a href=&#34;https://mastering-shiny.org/index.html&#34;&gt;Mastering Shiny&lt;/a&gt; by Hadley Wickkham, while still in development, is now much more advanced than the first time I looked into it for a project during my MSc program in late 2019. With my new knowledge on Git I even made a &lt;a href=&#34;https://github.com/hadley/mastering-shiny/pull/350&#34;&gt;pull request&lt;/a&gt; to contribute to the book (albeit only a small fix)!&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;I finally managed to finish editing a video of a canoeing weekend in August (see below). The trip was a way for our dragonboat group to keep paddling on a weekend that would otherwise be spent on the river Main competing in the Frankfurt Museumsuferfest. Hopefully the vaccinations go ahead fast so that we can return to normality by end of August 2021!&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;With 2021 it seems we will have new legislation on drones, which may require getting a license. Since this is currently possible for free at the &lt;a href=&#34;https://lba-openuav.de/&#34;&gt;Luftfahrtbundesamt&lt;/a&gt;, I also did the online training for the A1/A3 open sub category. New travels and amazing travel videos to come soon!&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Since Monday I am back in the (home) office, but the lockdown will continue until at least the end of the month. So more (forced) time for getting things done!&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/cguG88gxmrs&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
  </channel>
</rss>
